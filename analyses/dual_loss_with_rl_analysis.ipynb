{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e2b35a5",
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import importlib\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "PROJECT_ROOT = Path.cwd().resolve().parent if Path.cwd().name == 'analyses' else Path.cwd().resolve()\n",
        "ANALYSES_DIR = PROJECT_ROOT / 'analyses'\n",
        "OUT_DIR = ANALYSES_DIR / 'results'\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(PROJECT_ROOT))\n",
        "if str(ANALYSES_DIR) not in sys.path:\n",
        "    sys.path.insert(0, str(ANALYSES_DIR))\n",
        "\n",
        "import run_dual_loss_with_rl as runner\n",
        "runner = importlib.reload(runner)\n",
        "\n",
        "print('Project root:', PROJECT_ROOT)\n",
        "print('Output dir:', OUT_DIR)\n",
        "print('Runner:', runner.__file__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33f3e191",
      "metadata": {},
      "source": [
        "## Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85365b6e",
      "metadata": {},
      "outputs": [],
      "source": [
        "SCENARIO = 'discriminating'\n",
        "HORIZONS = [1, 4, 8]\n",
        "T = 1400\n",
        "WINDOW = 150\n",
        "\n",
        "TUNING_SEEDS = [0, 1, 2, 3]\n",
        "TEST_SEEDS = [4, 5, 6, 7, 8, 9]\n",
        "N_TRIALS = 35\n",
        "\n",
        "LINEX_A = 1.0\n",
        "KAPPA_GRID = np.array([0.01, 0.03, 0.1, 0.3, 1.0, 3.0, 8.0], dtype=float)\n",
        "\n",
        "LOSS_SECTIONS = [('mse', 'squared', 'mse'), ('linex', 'linex', 'linex')]\n",
        "METHODS = list(runner.ot.DEFAULT_METHOD_PARAMS.keys())\n",
        "\n",
        "print('Methods:', METHODS)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe96fbd1",
      "metadata": {},
      "source": [
        "## Tune Regular Methods By Horizon (Both Loss Sections)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e554d8b2",
      "metadata": {},
      "outputs": [],
      "source": [
        "tuning_rows = []\n",
        "tuned_by_loss_h = {}\n",
        "\n",
        "for loss_section, ens_loss, objective_metric in LOSS_SECTIONS:\n",
        "    tuned_by_h = {}\n",
        "    print(f'\\n=== Tuning section: {loss_section.upper()} ===')\n",
        "    for h in HORIZONS:\n",
        "        slices_h = []\n",
        "        for seed in TUNING_SEEDS:\n",
        "            data_t, forecasts_t, _, s_unc_t = runner.simulator.make_environment_and_forecasts(\n",
        "                T=T, horizons=HORIZONS, window=WINDOW, seed=seed, include_oracle=False, scenario=SCENARIO\n",
        "            )\n",
        "            y_t, F_t, s_t = runner.align_for_horizon(data_t['pi'], forecasts_t[h], s_unc_t, h)\n",
        "            slices_h.append((y_t, F_t, s_t))\n",
        "\n",
        "        tuned_h = runner.ot.tune_all_methods_optuna(\n",
        "            data_slices=slices_h,\n",
        "            methods=METHODS,\n",
        "            n_trials=N_TRIALS,\n",
        "            seed=42 + 100 * h,\n",
        "            loss=ens_loss,\n",
        "            linex_a=LINEX_A,\n",
        "            objective_metric=objective_metric,\n",
        "        )\n",
        "\n",
        "        tuned_by_h[h] = {m: dict(tuned_h[m].best_params) for m in METHODS}\n",
        "        for m in METHODS:\n",
        "            tuning_rows.append({\n",
        "                'loss_section': loss_section,\n",
        "                'horizon': float(h),\n",
        "                'method': m,\n",
        "                'best_params': str(tuned_h[m].best_params),\n",
        "                'tuning_objective': float(tuned_h[m].best_value),\n",
        "            })\n",
        "\n",
        "    tuned_by_loss_h[loss_section] = tuned_by_h\n",
        "\n",
        "tuning_df = pd.DataFrame(tuning_rows).sort_values(['loss_section', 'horizon', 'tuning_objective']).reset_index(drop=True)\n",
        "display(tuning_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7a2d165",
      "metadata": {},
      "source": [
        "## Evaluate On Test Seeds (Regular + RL Methods)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "717d867d",
      "metadata": {},
      "outputs": [],
      "source": [
        "all_rows = []\n",
        "all_diag_rows = []\n",
        "\n",
        "for loss_section, _, _ in LOSS_SECTIONS:\n",
        "    print(f'\\n=== Evaluating section: {loss_section.upper()} ===')\n",
        "    for seed in TEST_SEEDS:\n",
        "        rows, diag_rows = runner.evaluate_one_seed(\n",
        "            seed=seed,\n",
        "            horizons=HORIZONS,\n",
        "            T=T,\n",
        "            window=WINDOW,\n",
        "            scenario=SCENARIO,\n",
        "            loss_section=loss_section,\n",
        "            linex_a=LINEX_A,\n",
        "            params_map_by_h=tuned_by_loss_h[loss_section],\n",
        "            kappa_grid=KAPPA_GRID,\n",
        "        )\n",
        "        all_rows.extend(rows)\n",
        "        all_diag_rows.extend(diag_rows)\n",
        "\n",
        "summary_rows = runner.aggregate(all_rows)\n",
        "\n",
        "detailed_df = pd.DataFrame(all_rows).sort_values(['loss_section', 'horizon', 'seed', 'method']).reset_index(drop=True)\n",
        "summary_df = pd.DataFrame(summary_rows).sort_values(['loss_section', 'horizon', 'objective_mean']).reset_index(drop=True)\n",
        "diag_df = pd.DataFrame(all_diag_rows).sort_values(['loss_section', 'horizon', 'seed', 'method', 't']).reset_index(drop=True)\n",
        "\n",
        "print('Detailed rows:', len(detailed_df))\n",
        "print('Summary rows:', len(summary_df))\n",
        "print('Diagnostics rows:', len(diag_df))\n",
        "display(summary_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01d98ea3",
      "metadata": {},
      "source": [
        "## Save Outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aadfd8c0",
      "metadata": {},
      "outputs": [],
      "source": [
        "detailed_csv = OUT_DIR / 'dual_loss_full_detailed.csv'\n",
        "summary_csv = OUT_DIR / 'dual_loss_full_summary.csv'\n",
        "tuning_csv = OUT_DIR / 'dual_loss_full_tuned_params.csv'\n",
        "diag_csv = OUT_DIR / 'dual_loss_full_policy_diagnostics.csv'\n",
        "report_md = OUT_DIR / 'dual_loss_full_report.md'\n",
        "\n",
        "runner.write_csv(detailed_csv, detailed_df.to_dict(orient='records'))\n",
        "runner.write_csv(summary_csv, summary_df.to_dict(orient='records'))\n",
        "runner.write_csv(tuning_csv, tuning_df.to_dict(orient='records'))\n",
        "runner.write_csv(diag_csv, diag_df.to_dict(orient='records'))\n",
        "runner.write_report(report_md, summary_df.to_dict(orient='records'), tuning_df.to_dict(orient='records'), linex_a=LINEX_A)\n",
        "\n",
        "print('Wrote:', detailed_csv)\n",
        "print('Wrote:', summary_csv)\n",
        "print('Wrote:', tuning_csv)\n",
        "print('Wrote:', diag_csv)\n",
        "print('Wrote:', report_md)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e14a2524",
      "metadata": {},
      "source": [
        "## Plot: Objective Comparison By Horizon\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8239860d",
      "metadata": {},
      "outputs": [],
      "source": [
        "for loss_section in ['mse', 'linex']:\n",
        "    fig, axes = plt.subplots(1, len(HORIZONS), figsize=(5 * len(HORIZONS), 4), sharey=False)\n",
        "    if len(HORIZONS) == 1:\n",
        "        axes = [axes]\n",
        "    for ax, h in zip(axes, HORIZONS):\n",
        "        sub = summary_df[(summary_df['loss_section'] == loss_section) & (summary_df['horizon'] == float(h))].copy()\n",
        "        sub = sub.sort_values('objective_mean')\n",
        "        ax.barh(sub['method'], sub['objective_mean'])\n",
        "        ax.set_title(f'{loss_section.upper()} | h={h}')\n",
        "        ax.set_xlabel('Objective Mean')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38e4819b",
      "metadata": {},
      "source": [
        "## Plot: Concentration (Average HHI)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c21f5229",
      "metadata": {},
      "outputs": [],
      "source": [
        "for loss_section in ['mse', 'linex']:\n",
        "    fig, axes = plt.subplots(1, len(HORIZONS), figsize=(5 * len(HORIZONS), 4), sharey=True)\n",
        "    if len(HORIZONS) == 1:\n",
        "        axes = [axes]\n",
        "    for ax, h in zip(axes, HORIZONS):\n",
        "        sub = summary_df[(summary_df['loss_section'] == loss_section) & (summary_df['horizon'] == float(h))].copy()\n",
        "        sub = sub.sort_values('avg_hhi_mean', na_position='last')\n",
        "        ax.barh(sub['method'], sub['avg_hhi_mean'])\n",
        "        ax.set_title(f'{loss_section.upper()} | h={h}')\n",
        "        ax.set_xlabel('Average HHI')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5e10f9c",
      "metadata": {},
      "source": [
        "## RL Diagnostics: Rule Selection Shares\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6d9665f",
      "metadata": {},
      "outputs": [],
      "source": [
        "rule_diag = diag_df[diag_df['method'] == 'RLRuleBandit'].copy()\n",
        "if not rule_diag.empty:\n",
        "    shares = (\n",
        "        rule_diag.groupby(['loss_section', 'horizon', 'action_name'])\n",
        "        .size()\n",
        "        .reset_index(name='count')\n",
        "    )\n",
        "    shares['share'] = shares.groupby(['loss_section', 'horizon'])['count'].transform(lambda x: x / x.sum())\n",
        "\n",
        "    for loss_section in ['mse', 'linex']:\n",
        "        fig, axes = plt.subplots(1, len(HORIZONS), figsize=(5 * len(HORIZONS), 4), sharey=True)\n",
        "        if len(HORIZONS) == 1:\n",
        "            axes = [axes]\n",
        "        for ax, h in zip(axes, HORIZONS):\n",
        "            sub = shares[(shares['loss_section'] == loss_section) & (shares['horizon'] == float(h))].sort_values('share')\n",
        "            ax.barh(sub['action_name'], sub['share'])\n",
        "            ax.set_title(f'Rule Shares | {loss_section.upper()} h={h}')\n",
        "            ax.set_xlabel('Share')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "else:\n",
        "    print('No rule-bandit diagnostics available.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2e54b02",
      "metadata": {},
      "source": [
        "## RL Diagnostics: Kappa Trajectory (Example Seed/Horizon)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8858085",
      "metadata": {},
      "outputs": [],
      "source": [
        "kdiag = diag_df[diag_df['method'] == 'RLKappaBandit'].copy()\n",
        "if not kdiag.empty:\n",
        "    for loss_section in ['mse', 'linex']:\n",
        "        seed0 = float(TEST_SEEDS[0])\n",
        "        h0 = float(HORIZONS[0])\n",
        "        sub = kdiag[(kdiag['loss_section'] == loss_section) & (kdiag['seed'] == seed0) & (kdiag['horizon'] == h0)]\n",
        "\n",
        "        fig, ax1 = plt.subplots(figsize=(10, 3))\n",
        "        ax1.plot(sub['t'], sub['kappa'], label='kappa_t')\n",
        "        ax1.set_title(f'Kappa Path | {loss_section.upper()} | seed={int(seed0)} h={int(h0)}')\n",
        "        ax1.set_xlabel('t')\n",
        "        ax1.set_ylabel('kappa_t')\n",
        "        ax1.legend(loc='upper left')\n",
        "\n",
        "        ax2 = ax1.twinx()\n",
        "        ax2.plot(sub['t'], sub['hhi_t'], color='tab:orange', alpha=0.6, label='HHI_t')\n",
        "        ax2.set_ylabel('HHI_t')\n",
        "        ax2.legend(loc='upper right')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "else:\n",
        "    print('No kappa-bandit diagnostics available.')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ensemble",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
