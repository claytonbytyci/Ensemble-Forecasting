{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation Ensembling Analysis (With Diagnostics)\n",
    "\n",
    "This notebook runs a full simulation study and **uses the evaluation helpers** to:\n",
    "- compare losses across ensemble methods\n",
    "- plot cumulative/rolling losses\n",
    "- inspect concentration (HHI) dynamics\n",
    "- summarize what is happening along the way\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import csv\n",
    "import math\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=SyntaxWarning)\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().resolve().parent if Path.cwd().name == \"analyses\" else Path.cwd().resolve()\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "NOTEBOOK_DIR = Path.cwd().resolve() if Path.cwd().name == \"analyses\" else PROJECT_ROOT / \"analyses\"\n",
    "OUT_DIR = NOTEBOOK_DIR / \"results\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "from src.data import simulator\n",
    "from src.ensemblers import ensemblers\n",
    "from src.evaluation import evaluation_helpers as eh\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Output dir: {OUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y: np.ndarray, yhat: np.ndarray) -> float:\n",
    "    e = y - yhat\n",
    "    return float(np.mean(e * e))\n",
    "\n",
    "\n",
    "def mae(y: np.ndarray, yhat: np.ndarray) -> float:\n",
    "    return float(np.mean(np.abs(y - yhat)))\n",
    "\n",
    "\n",
    "def linex(y: np.ndarray, yhat: np.ndarray, a: float = 1.0) -> float:\n",
    "    e = y - yhat\n",
    "    return float(np.mean(np.exp(a * e) - a * e - 1.0))\n",
    "\n",
    "\n",
    "def hhi(weights: np.ndarray) -> float:\n",
    "    w = np.asarray(weights, dtype=float)\n",
    "    if w.ndim != 2:\n",
    "        return math.nan\n",
    "    valid = np.all(np.isfinite(w), axis=1)\n",
    "    if not np.any(valid):\n",
    "        return math.nan\n",
    "    return float(np.mean(np.sum(w[valid] ** 2, axis=1)))\n",
    "\n",
    "\n",
    "def helpers_from_source(path: Path) -> List[str]:\n",
    "    tree = ast.parse(path.read_text(), filename=str(path))\n",
    "    names: List[str] = []\n",
    "    for node in tree.body:\n",
    "        if isinstance(node, (ast.FunctionDef, ast.ClassDef)) and not node.name.startswith(\"_\"):\n",
    "            names.append(node.name)\n",
    "    return sorted(names)\n",
    "\n",
    "\n",
    "def align_for_horizon(\n",
    "    pi: np.ndarray,\n",
    "    forecasts_h: np.ndarray,\n",
    "    s_unc: np.ndarray,\n",
    "    h: int,\n",
    ") -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    y_target = pi[h:]\n",
    "    F = forecasts_h[:-h]\n",
    "    s = s_unc[:-h]\n",
    "    mask = np.isfinite(y_target) & np.isfinite(s) & np.all(np.isfinite(F), axis=1)\n",
    "    return y_target[mask], F[mask], s[mask]\n",
    "\n",
    "\n",
    "def evaluate_one_seed(seed: int, horizons: List[int], T: int, window: int) -> List[Dict[str, float]]:\n",
    "    data, forecasts_by_h, names, s_unc = simulator.make_environment_and_forecasts(\n",
    "        T=T, horizons=horizons, window=window, seed=seed, include_oracle=False\n",
    "    )\n",
    "    pi = data[\"pi\"]\n",
    "    rows: List[Dict[str, float]] = []\n",
    "\n",
    "    for h in horizons:\n",
    "        y, F, s = align_for_horizon(pi, forecasts_by_h[h], s_unc, h)\n",
    "        individual_mses = [mse(y, F[:, i]) for i in range(F.shape[1])]\n",
    "        best_idx = int(np.argmin(individual_mses))\n",
    "        best_individual_mse = float(individual_mses[best_idx])\n",
    "\n",
    "        configs = {\n",
    "            \"Mean\": ensemblers.MeanEnsembler(),\n",
    "            \"Median\": ensemblers.MedianEnsembler(),\n",
    "            \"OGDVanilla\": ensemblers.OGDVanilla(eta=0.05, loss=\"squared\"),\n",
    "            \"MWUMVanilla\": ensemblers.MWUMVanilla(eta=0.3, loss=\"squared\"),\n",
    "            \"OGDBoth\": ensemblers.OGDConcentrationBoth(eta=0.05, kappa=0.8, loss=\"squared\"),\n",
    "            \"OGDConcOnly\": ensemblers.OGDConcentrationOnly(kappa=0.8, loss=\"squared\"),\n",
    "            \"MWUMBothKL\": ensemblers.MWUMBothKL(eta=0.3, kappa=0.8, loss=\"squared\"),\n",
    "            \"MWUMConcOnlyKL\": ensemblers.MWUMConcentrationOnlyKL(kappa=0.8, loss=\"squared\"),\n",
    "        }\n",
    "\n",
    "        for name, model in configs.items():\n",
    "            needs_state = name in {\"OGDBoth\", \"OGDConcOnly\", \"MWUMBothKL\", \"MWUMConcOnlyKL\"}\n",
    "            result = model.run(F, y, s=s if needs_state else None)\n",
    "            rows.append({\n",
    "                \"seed\": float(seed),\n",
    "                \"horizon\": float(h),\n",
    "                \"method\": name,\n",
    "                \"n_obs\": float(y.size),\n",
    "                \"mse\": mse(y, result.yhat),\n",
    "                \"mae\": mae(y, result.yhat),\n",
    "                \"linex_a1\": linex(y, result.yhat, a=1.0),\n",
    "                \"avg_hhi\": hhi(result.weights),\n",
    "                \"best_individual_mse\": best_individual_mse,\n",
    "                \"best_individual_idx\": float(best_idx),\n",
    "            })\n",
    "\n",
    "    return rows\n",
    "\n",
    "\n",
    "def aggregate(rows: List[Dict[str, float]]) -> pd.DataFrame:\n",
    "    out: List[Dict[str, float]] = []\n",
    "    keys = sorted({(r[\"horizon\"], r[\"method\"]) for r in rows})\n",
    "    for horizon, method in keys:\n",
    "        grp = [r for r in rows if r[\"horizon\"] == horizon and r[\"method\"] == method]\n",
    "        mses = np.array([r[\"mse\"] for r in grp], dtype=float)\n",
    "        maes = np.array([r[\"mae\"] for r in grp], dtype=float)\n",
    "        linexes = np.array([r[\"linex_a1\"] for r in grp], dtype=float)\n",
    "        hhis = np.array([r[\"avg_hhi\"] for r in grp], dtype=float)\n",
    "        bests = np.array([r[\"best_individual_mse\"] for r in grp], dtype=float)\n",
    "\n",
    "        finite_hhi = hhis[np.isfinite(hhis)]\n",
    "        avg_hhi_mean = float(np.mean(finite_hhi)) if finite_hhi.size else math.nan\n",
    "\n",
    "        out.append({\n",
    "            \"horizon\": horizon,\n",
    "            \"method\": method,\n",
    "            \"mse_mean\": float(np.mean(mses)),\n",
    "            \"mse_std\": float(np.std(mses)),\n",
    "            \"mae_mean\": float(np.mean(maes)),\n",
    "            \"linex_mean\": float(np.mean(linexes)),\n",
    "            \"avg_hhi_mean\": avg_hhi_mean,\n",
    "            \"avg_excess_mse_vs_best_individual\": float(np.mean(mses - bests)),\n",
    "        })\n",
    "    df = pd.DataFrame(out).sort_values([\"horizon\", \"mse_mean\"]).reset_index(drop=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) What Helpers Do We Have?\n",
    "\n",
    "Inventory of helper functions/classes in the simulation, ensembling, and evaluation modules.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIM_HELPERS = helpers_from_source(PROJECT_ROOT / \"src\" / \"data\" / \"simulator.py\")\n",
    "ENS_HELPERS = helpers_from_source(PROJECT_ROOT / \"src\" / \"ensemblers\" / \"ensemblers.py\")\n",
    "EVAL_HELPERS = helpers_from_source(PROJECT_ROOT / \"src\" / \"evaluation\" / \"evaluation_helpers.py\")\n",
    "\n",
    "display(pd.DataFrame({\"src.data.simulator\": pd.Series(SIM_HELPERS)}))\n",
    "display(pd.DataFrame({\"src.ensemblers.ensemblers\": pd.Series(ENS_HELPERS)}))\n",
    "display(pd.DataFrame({\"src.evaluation.evaluation_helpers\": pd.Series(EVAL_HELPERS)}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Simulated Macro Background EDA\n",
    "\n",
    "Before evaluating ensemblers, inspect the simulated macro environment (levels, regimes, uncertainty, and cross-variable relationships).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED_BG = 3\n",
    "T_BG = 2200\n",
    "\n",
    "data_bg, _, _, s_unc_bg = simulator.make_environment_and_forecasts(\n",
    "    T=T_BG, horizons=[1], window=150, seed=SEED_BG, include_oracle=False\n",
    ")\n",
    "\n",
    "df_bg = pd.DataFrame({\n",
    "    \"pi\": data_bg[\"pi\"],\n",
    "    \"x\": data_bg[\"x\"],\n",
    "    \"i\": data_bg[\"i\"],\n",
    "    \"u\": data_bg[\"u\"],\n",
    "    \"sigma_pi\": data_bg[\"sigma_pi\"],\n",
    "    \"regime\": data_bg[\"regime\"],\n",
    "    \"state_uncertainty\": s_unc_bg,\n",
    "})\n",
    "\n",
    "print(f\"Background sample size: {len(df_bg)}\")\n",
    "display(df_bg.head())\n",
    "display(df_bg[[\"pi\",\"x\",\"i\",\"u\",\"sigma_pi\",\"state_uncertainty\"]].describe().T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regime_share = (\n",
    "    df_bg[\"regime\"].value_counts(normalize=True).sort_index().rename(\"share\").to_frame()\n",
    ")\n",
    "regime_share.index = [f\"regime_{int(i)}\" for i in regime_share.index]\n",
    "display(regime_share)\n",
    "\n",
    "corr = df_bg[[\"pi\",\"x\",\"i\",\"u\",\"sigma_pi\",\"state_uncertainty\"]].corr()\n",
    "display(corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-series view with regime path\n",
    "t = np.arange(len(df_bg))\n",
    "fig, axes = plt.subplots(6, 1, figsize=(14, 14), sharex=True)\n",
    "\n",
    "series = [\"pi\", \"x\", \"i\", \"u\", \"sigma_pi\", \"state_uncertainty\"]\n",
    "colors = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\", \"#8c564b\"]\n",
    "for ax, sname, c in zip(axes, series, colors):\n",
    "    ax.plot(t, df_bg[sname].to_numpy(), color=c, linewidth=1.0)\n",
    "    ax.set_ylabel(sname)\n",
    "    ax.grid(alpha=0.2)\n",
    "\n",
    "axr = axes[0].twinx()\n",
    "axr.step(t, df_bg[\"regime\"].to_numpy(), where=\"post\", color=\"black\", alpha=0.25, linewidth=0.8)\n",
    "axr.set_ylabel(\"regime\", color=\"black\")\n",
    "axr.set_yticks([0,1,2])\n",
    "\n",
    "axes[-1].set_xlabel(\"time\")\n",
    "fig.suptitle(\"Simulated Macro Background (with regime path)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution and regime-conditional views\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 9))\n",
    "\n",
    "axes[0,0].hist(df_bg[\"pi\"], bins=50, color=\"#1f77b4\", alpha=0.8)\n",
    "axes[0,0].set_title(\"Inflation (pi) distribution\")\n",
    "\n",
    "axes[0,1].hist(df_bg[\"sigma_pi\"], bins=50, color=\"#9467bd\", alpha=0.8)\n",
    "axes[0,1].set_title(\"Inflation uncertainty (sigma_pi) distribution\")\n",
    "\n",
    "for r, c in zip(sorted(df_bg[\"regime\"].unique()), [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\"]):\n",
    "    sub = df_bg[df_bg[\"regime\"] == r]\n",
    "    axes[1,0].scatter(sub[\"x\"], sub[\"pi\"], s=8, alpha=0.25, color=c, label=f\"regime {int(r)}\")\n",
    "axes[1,0].set_title(\"Phillips-style scatter: pi vs x by regime\")\n",
    "axes[1,0].set_xlabel(\"x\")\n",
    "axes[1,0].set_ylabel(\"pi\")\n",
    "axes[1,0].legend()\n",
    "\n",
    "for r, c in zip(sorted(df_bg[\"regime\"].unique()), [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\"]):\n",
    "    sub = df_bg[df_bg[\"regime\"] == r]\n",
    "    axes[1,1].hist(sub[\"pi\"], bins=35, alpha=0.35, color=c, density=True, label=f\"regime {int(r)}\")\n",
    "axes[1,1].set_title(\"Inflation distribution by regime\")\n",
    "axes[1,1].legend()\n",
    "\n",
    "for ax in axes.ravel():\n",
    "    ax.grid(alpha=0.2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA Interpretation\n",
    "- The regime process is persistent (long stretches in each state), not i.i.d.\n",
    "- `sigma_pi` and `state_uncertainty` vary substantially over time, motivating state-dependent regularization (`lambda_t = kappa * s_t`).\n",
    "- The `pi`-`x` relationship changes by regime, so static linear pooling can be suboptimal relative to adaptive ensembling.\n",
    "- Distribution shifts and volatility clustering imply online methods should react differently across tranquil vs turbulent intervals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Multi-Seed Aggregate Experiment\n",
    "\n",
    "Run the full experiment across several random seeds to get stable ranking statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEEDS = list(range(10))\n",
    "HORIZONS = [1, 4, 8]\n",
    "T = 1400\n",
    "WINDOW = 150\n",
    "\n",
    "all_rows: List[Dict[str, float]] = []\n",
    "for seed in SEEDS:\n",
    "    all_rows.extend(evaluate_one_seed(seed=seed, horizons=HORIZONS, T=T, window=WINDOW))\n",
    "\n",
    "agg_df = aggregate(all_rows)\n",
    "all_df = pd.DataFrame(all_rows)\n",
    "\n",
    "print(f\"Detailed rows: {len(all_df)}\")\n",
    "print(f\"Aggregated rows: {len(agg_df)}\")\n",
    "display(agg_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Interpretation\n",
    "\n",
    "Below we print the best method by MSE per horizon from the aggregate table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for h in HORIZONS:\n",
    "    sub = agg_df[agg_df[\"horizon\"] == float(h)].sort_values(\"mse_mean\")\n",
    "    top = sub.iloc[0]\n",
    "    print(\n",
    "        f\"h={h}: best={top['method']} | MSE={top['mse_mean']:.4f}, MAE={top['mae_mean']:.4f}, \\\n",
    "LINEX={top['linex_mean']:.4f}, avg HHI={top['avg_hhi_mean']:.4f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Walkthrough With Evaluation Helpers (Single Scenario)\n",
    "\n",
    "Now we use `src/evaluation/evaluation_helpers.py` directly to **plot and diagnose what happens over time** for one representative run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED_DEMO = 0\n",
    "H_DEMO = 4\n",
    "\n",
    "data_demo, forecasts_by_h_demo, names_demo, s_unc_demo = simulator.make_environment_and_forecasts(\n",
    "    T=T, horizons=HORIZONS, window=WINDOW, seed=SEED_DEMO, include_oracle=False\n",
    ")\n",
    "\n",
    "y_demo, F_demo, s_demo = align_for_horizon(data_demo[\"pi\"], forecasts_by_h_demo[H_DEMO], s_unc_demo, H_DEMO)\n",
    "\n",
    "models_demo = {\n",
    "    \"Mean\": ensemblers.MeanEnsembler(),\n",
    "    \"Median\": ensemblers.MedianEnsembler(),\n",
    "    \"OGDVanilla\": ensemblers.OGDVanilla(eta=0.05, loss=\"squared\"),\n",
    "    \"MWUMVanilla\": ensemblers.MWUMVanilla(eta=0.3, loss=\"squared\"),\n",
    "    \"OGDBoth\": ensemblers.OGDConcentrationBoth(eta=0.05, kappa=0.8, loss=\"squared\"),\n",
    "    \"OGDConcOnly\": ensemblers.OGDConcentrationOnly(kappa=0.8, loss=\"squared\"),\n",
    "    \"MWUMBothKL\": ensemblers.MWUMBothKL(eta=0.3, kappa=0.8, loss=\"squared\"),\n",
    "    \"MWUMConcOnlyKL\": ensemblers.MWUMConcentrationOnlyKL(kappa=0.8, loss=\"squared\"),\n",
    "}\n",
    "\n",
    "yhats_demo: Dict[str, np.ndarray] = {}\n",
    "weights_demo: Dict[str, np.ndarray] = {}\n",
    "for name, model in models_demo.items():\n",
    "    needs_state = name in {\"OGDBoth\", \"OGDConcOnly\", \"MWUMBothKL\", \"MWUMConcOnlyKL\"}\n",
    "    res = model.run(F_demo, y_demo, s=s_demo if needs_state else None)\n",
    "    yhats_demo[name] = res.yhat\n",
    "    weights_demo[name] = res.weights\n",
    "\n",
    "print(f\"Demo setup: seed={SEED_DEMO}, horizon={H_DEMO}, observations={len(y_demo)}, experts={F_demo.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation helper: summary loss table vs best individual forecaster\n",
    "table_demo = eh.loss_table(\n",
    "    y=y_demo,\n",
    "    F_individual=F_demo,\n",
    "    yhats=yhats_demo,\n",
    "    metric=\"mse\",\n",
    "    include_best_forecaster=True,\n",
    "    forecaster_names=names_demo,\n",
    ")\n",
    "display(table_demo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What This Table Says\n",
    "- The top row is the lowest MSE in this demo scenario.\n",
    "- The best-individual row is the strongest single forecaster benchmark.\n",
    "- Ensemble rows below that show whether online weighting beats static/individual baselines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation helper: cumulative squared loss trajectories\n",
    "eh.plot_loss_over_time(\n",
    "    y=y_demo,\n",
    "    yhats=yhats_demo,\n",
    "    loss=\"sq\",\n",
    "    mode=\"cumulative\",\n",
    "    title=f\"Cumulative Squared Loss (seed={SEED_DEMO}, h={H_DEMO})\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation helper: rolling loss to see local regime-performance changes\n",
    "eh.plot_loss_over_time(\n",
    "    y=y_demo,\n",
    "    yhats=yhats_demo,\n",
    "    loss=\"sq\",\n",
    "    mode=\"rolling\",\n",
    "    rolling_window=60,\n",
    "    title=f\"Rolling Squared Loss (window=60, seed={SEED_DEMO}, h={H_DEMO})\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation helper: concentration dynamics (HHI) from ensemble weights\n",
    "weights_plot = {k: v for k, v in weights_demo.items() if np.isfinite(v).all()}\n",
    "eh.plot_hhi_over_time(\n",
    "    weights_dict=weights_plot,\n",
    "    title=f\"Weight Concentration (HHI) Over Time (seed={SEED_DEMO}, h={H_DEMO})\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Programmatic narrative from the demo outputs\n",
    "winner = table_demo.iloc[0]\n",
    "runner = table_demo.iloc[1]\n",
    "\n",
    "hhi_avg = {name: eh.hhi_from_weights(W) for name, W in weights_plot.items()}\n",
    "hhi_mean = {name: float(np.nanmean(v)) for name, v in hhi_avg.items()}\n",
    "most_concentrated = max(hhi_mean, key=hhi_mean.get)\n",
    "most_diversified = min(hhi_mean, key=hhi_mean.get)\n",
    "\n",
    "print(\"Interpretation:\")\n",
    "print(f\"- Best method in this demo (by MSE): {winner['Model']} ({winner['MSE']:.4f})\")\n",
    "print(f\"- Runner-up: {runner['Model']} ({runner['MSE']:.4f})\")\n",
    "print(f\"- Most concentrated weighting (highest avg HHI): {most_concentrated} ({hhi_mean[most_concentrated]:.4f})\")\n",
    "print(f\"- Most diversified weighting (lowest avg HHI): {most_diversified} ({hhi_mean[most_diversified]:.4f})\")\n",
    "print(\"- In cumulative-loss plots, flatter slope means better ongoing forecast performance.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Persist Results\n",
    "\n",
    "Save detailed/summary metrics and a markdown report for downstream use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv(path: Path, rows: List[Dict[str, float]]) -> None:\n",
    "    if not rows:\n",
    "        return\n",
    "    fieldnames = list(rows[0].keys())\n",
    "    with path.open(\"w\", newline=\"\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        w.writeheader()\n",
    "        w.writerows(rows)\n",
    "\n",
    "\n",
    "def write_report(path: Path, sim_helpers: List[str], ens_helpers: List[str], eval_helpers: List[str], agg_df: pd.DataFrame) -> None:\n",
    "    lines: List[str] = []\n",
    "    lines.append(\"# Simulation Ensembling Analysis\\n\")\n",
    "    lines.append(\"## Module Helper Inventory\\n\")\n",
    "\n",
    "    lines.append(\"### `src.data.simulator`\")\n",
    "    lines.extend([f\"- `{x}`\" for x in sim_helpers])\n",
    "\n",
    "    lines.append(\"\\n### `src.ensemblers.ensemblers`\")\n",
    "    lines.extend([f\"- `{x}`\" for x in ens_helpers])\n",
    "\n",
    "    lines.append(\"\\n### `src.evaluation.evaluation_helpers`\")\n",
    "    lines.extend([f\"- `{x}`\" for x in eval_helpers])\n",
    "\n",
    "    lines.append(\"\\n## Aggregated Results\")\n",
    "    for h in sorted(agg_df[\"horizon\"].unique()):\n",
    "        lines.append(f\"\\n### Horizon h={int(h)}\")\n",
    "        sub = agg_df[agg_df[\"horizon\"] == h].sort_values(\"mse_mean\")\n",
    "        for _, r in sub.iterrows():\n",
    "            lines.append(\n",
    "                f\"- {r['method']}: MSE={r['mse_mean']:.4f} (std {r['mse_std']:.4f}), MAE={r['mae_mean']:.4f}, LINEX={r['linex_mean']:.4f}, avg HHI={r['avg_hhi_mean']:.4f}\"\n",
    "            )\n",
    "\n",
    "    path.write_text(\"\\n\".join(lines) + \"\\n\")\n",
    "\n",
    "\n",
    "detailed_csv = OUT_DIR / \"simulation_ensemble_detailed.csv\"\n",
    "summary_csv = OUT_DIR / \"simulation_ensemble_summary.csv\"\n",
    "report_md = OUT_DIR / \"simulation_ensemble_report.md\"\n",
    "\n",
    "write_csv(detailed_csv, all_df.to_dict(orient=\"records\"))\n",
    "write_csv(summary_csv, agg_df.to_dict(orient=\"records\"))\n",
    "write_report(report_md, SIM_HELPERS, ENS_HELPERS, EVAL_HELPERS, agg_df)\n",
    "\n",
    "print(f\"Wrote: {detailed_csv}\")\n",
    "print(f\"Wrote: {summary_csv}\")\n",
    "print(f\"Wrote: {report_md}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}